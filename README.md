
# ğŸš€ deepthon_pipeline

<div align="center">
  <img src="assets/img.png" alt="Deepthon Pipeline Header" width="600">
</div>
<div align="center">

## An end-to-end deep learning pipeline built on top of **[deepthon](https://github.com/Ibraheem-Al-hafith/deepthon.git)** ğŸ§  â€” a lightweight deep learning library written *from scratch* using **NumPy**.


âœ¨ This project demonstrates how to go from **download raw data â†’ preprocessing â†’ training â†’ evaluation â†’ interactive demo & cli commands** using a clean, modular, and hackable design.
</div>

---

## ğŸ§© Benchmarks Included


| Task             | Type                       | Description                                |
| ---------------- | -------------------------- | ------------------------------------------ |
| ğŸ©º Breast Cancer | Binary Classification      | Predict malignant vs benign tumors         |
| âœï¸ MNIST         | Multi-class Classification | Handwritten digit recognition (0â€“9)        |
| âš¡ Turbine Energy | Regression                 | Predict energy generation from sensor data |


---

## ğŸ› ï¸ Installation

### ğŸ“ we must setup the two dependencies ğŸ“

### 1. Setup Pipeline (`deepthon_pipeline`)

#### ğŸªŸ Windows (Using `uv`)

Open PowerShell and run:

**Install uv**
```powershell
powershell -c "irmo https://astral.sh/uv/install.ps1 | iex"

```

**if the previous command fails:**
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"

```

**Setup project**
```powershell
git clone https://github.com/Ibraheem-Al-hafith/deepthon_pipeline.git
cd deepthon_pipeline
uv venv
.venv\Scripts\activate
uv pip install -e .

```

#### ğŸ Mac / ğŸ§ Linux (Using `uv`)

Open your terminal and run:

**Install uv**

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh

```

**Setup project**

```
git clone https://github.com/Ibraheem-Al-hafith/deepthon_pipeline.git
cd deepthon_pipeline
uv sync

```

---

## ğŸ–¥ï¸ GUI Usage

For a more visual and interactive experience, you can launch the built-in web dashboard powered by **Gradio**. This allows you to upload samples and see model predictions in real-time.

**To launch the interface:**

```bash
python -m src.deepthon_pipeline.ui.app serve

```

### ğŸ“º Demo Video

https://github.com/user-attachments/assets/bc7e224f-9b6c-44ff-a518-4f549596f38d


---

## ğŸ§ª CLI Usage

The pipeline uses a positional CLI structure for speed and clarity.

```bash
python -m src.deepthon_pipeline.cli.main <command> [args] [options]

```

### ğŸ”¹ `train`

Train models based on your YAML config.

Run all datasets and models in config

```bash
python -m src.deepthon_pipeline.cli.main train configs/config.yaml
```

Run specific dataset (uses default 'all' for models)

```bash
python -m src.deepthon_pipeline.cli.main train configs/config.yaml cancer
```

Run specific dataset and specific model size

```bash
python -m src.deepthon_pipeline.cli.main train configs/config.yaml cancer --model tiny
```

### ğŸ”¹ `test-all` (*recommended even when run a single training loop*)

Evaluate all models generated by an experiment config.

```bash
python -m src.deepthon_pipeline.cli.main test-all configs/config.yaml

```

### ğŸ”¹ `test`

Evaluate a specific saved checkpoint.

```bash
# Syntax: test <config> <checkpoint> <dataset> <model>
python -m src.deepthon_pipeline.cli.main test configs/config.yaml runs/exp/model.npz cancer tiny

```

---

## âš™ï¸ Example Configuration (`config.yaml`)
### (NOTE): see [./configs/config.yaml](./configs/config.yaml) for the complete yaml template.

```yaml
experiment: turbines_experiment
datasets:
  mnist:
    name: mnist
    input_dim: 784
    output_dim: 10
    urls:
      train_images: [https://raw.githubusercontent.com/fgnt/mnist/master/train-images-idx3-ubyte.gz](https://raw.githubusercontent.com/fgnt/mnist/master/train-images-idx3-ubyte.gz)
      train_labels: [https://raw.githubusercontent.com/fgnt/mnist/master/train-labels-idx1-ubyte.gz](https://raw.githubusercontent.com/fgnt/mnist/master/train-labels-idx1-ubyte.gz)
    train_config:
      loss_fn: CCE
      metric: f1
  cancer:
    name: cancer
    input_dim: 30
    output_dim: 1
    train_config:
      loss_fn: BCE
      metric: f1

model:
  tiny:
    type: sequential
    architecture:
      - [null, 64, relu]
      - [batchnorm, 64]
      - [Dropout, 0.2]
      - [64, null, linear]

training:
  batch_size: 64
  epochs: 100
  optimizer:
    name: adamw
    lr: 0.001

```

---

## ğŸ—‚ï¸ Project Structure

```text
deepthon_pipeline/
â”œâ”€ assets/      ğŸ¨ Images & Brand
â”œâ”€ configs/     ğŸ“„ Experiment YAMLs
â”œâ”€ logs/        ğŸ“„ Experiment log file
â”œâ”€ src/
â”‚  â””â”€ deepthon_pipeline/
â”‚     â”œâ”€ cli/       ğŸ–¥ï¸ CLI Commands
â”‚     â”œâ”€ data/      ğŸ“¦ Loaders & Preprocessing
â”‚     â”œâ”€ models/    ğŸ§  Architecture Registry
â”‚     â”œâ”€ training/  ğŸƒ Runner & Trainer logic
â”‚     â””â”€ utils/     ğŸ”§ Logging & Helpers
â””â”€ tests/       ğŸ§ª Pytest suite

```

---

## ğŸ¤ Contributing

PRs are welcome! ğŸ‰

* Add new datasets via the dataset registry.
* Add new models via the model registry.
* Keep code clean, small, and readable.

---

## ğŸ“œ License

MIT License

---

## â¤ï¸ Final Note

This project is intentionally **simple, transparent, and hackable**. If you want to *learn how deep learning works under the hood*, this is for you.

**Happy hacking! ğŸš€ğŸ§ **
